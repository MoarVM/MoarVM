#include "moar.h"
#include <dasm_proto.h>
#include <dasm_x86.h>
#include "emit.h"

#ifdef _MSC_VER
#pragma warning( disable : 4129 )
#endif

|.arch x64
|.actionlist actions
|.section code
|.globals MVM_JIT_LABEL_

/* type declarations */
|.type REGISTER, MVMRegister
|.type ARGCTX, MVMArgProcContext
|.type CAPTURE, MVMCallCapture
|.type STATICFRAME, MVMStaticFrame
|.type P6OPAQUE, MVMP6opaque
|.type P6OBODY, MVMP6opaqueBody
|.type MVMITER, MVMIter
|.type MVMINSTANCE, MVMInstance
|.type OBJECT, MVMObject
|.type STOOGE, MVMObjectStooge
|.type COLLECTABLE, MVMCollectable
|.type STABLE, MVMSTable
|.type REPR, MVMREPROps
|.type LEXOTIC, MVMLexotic
|.type STRING, MVMString*
|.type OBJECTPTR, MVMObject*
|.type CONTAINERSPEC, MVMContainerSpec
|.type STORAGESPEC, MVMStorageSpec
|.type HLLCONFIG, MVMHLLConfig;
|.type SCREFBODY, MVMSerializationContextBody
|.type U8, MVMuint8
|.type U16, MVMuint16
|.type U32, MVMuint32
|.type U64, MVMuint64



/* Static allocation of relevant types to registers. I pick
 * callee-save registers for efficiency. It is likely we'll be calling
 * quite a C functions, and this saves us the trouble of storing
 * them. Moreover, C compilers preferentially do not use callee-saved
 * registers, and so in most cases, these won't be touched at all. */
|.type TC, MVMThreadContext, r14
/* Alternative base pointer. I'll be using this often, so picking rbx
 * here rather than the extended registers will lead to smaller
 * bytecode */
|.type WORK, MVMRegister, rbx
|.type FRAME, MVMFrame, r12
|.type CU, MVMCompUnit, r13




const MVMint32 MVM_jit_support(void) {
    return 1;
}

const unsigned char * MVM_jit_actions(void) {
    return actions;
}

const unsigned int MVM_jit_num_globals(void) {
    return MVM_JIT_LABEL__MAX;
}


/* C Call argument registers */
|.if WIN32
|.define ARG1, rcx
|.define ARG2, rdx
|.define ARG3, r8
|.define ARG4, r9
|.else
|.define ARG1, rdi
|.define ARG2, rsi
|.define ARG3, rdx
|.define ARG4, rcx
|.define ARG5, r8
|.define ARG6, r9
|.endif

/* C call argument registers for floating point */
|.if WIN32
|.define ARG1F, xmm0
|.define ARG2F, xmm1
|.define ARG3F, xmm2
|.define ARG4F, xmm3
|.else
|.define ARG1F, xmm0
|.define ARG2F, xmm1
|.define ARG3F, xmm2
|.define ARG4F, xmm3
|.define ARG5F, xmm4
|.define ARG6F, xmm5
|.define ARG7F, xmm6
|.define ARG8F, xmm7
|.endif

/* Special register for the function to be invoked
 * (chosen because it isn't involved in argument passing
 *  and volatile) */
|.define FUNCTION, r10
/* all-purpose temporary registers */
|.define TMP1, rcx
|.define TMP2, rdx
|.define TMP3, r8
|.define TMP4, r9
|.define TMP5, r10
|.define TMP6, r11
/* same, but 32 bits wide */
|.define TMP1d, ecx
|.define TMP2d, edx
|.define TMP3d, r8d
|.define TMP4d, r9d
|.define TMP5d, r10d
|.define TMP6d, r11d
/* and 16 bits wide */
|.define TMP1w, cx
|.define TMP2w, dx
|.define TMP3w, r8w
|.define TMP4w, r9w
|.define TMP5w, r10w
|.define TMP6w, r11w
/* and 8 bits for good measure */
|.define TMP1b, cl
|.define TMP2b, dl
|.define TMP3b, r8b
|.define TMP4b, r9b
|.define TMP5b, r10b
|.define TMP6b, r11b


/* return value */
|.define RV, rax
|.define RVF, xmm0


|.macro callp, funcptr
| mov64 FUNCTION, (uintptr_t)funcptr
| call FUNCTION
|.endmacro


|.macro check_wb, root, ref;
| test word COLLECTABLE:root->flags, MVM_CF_SECOND_GEN;
| setnz al;
| cmp ref, 0x0;
| setne ah;
| test ah, al;
| setnz al;
| test word COLLECTABLE:ref->flags, MVM_CF_SECOND_GEN;
| setz ah;
| test ah, al;
|.endmacro;

|.macro hit_wb, obj
| mov ARG1, TC;
| mov ARG2, obj;
| callp &MVM_gc_write_barrier_hit;
|.endmacro

|.macro get_spesh_slot, reg, idx;
| mov reg, FRAME->effective_spesh_slots;
| mov reg, OBJECTPTR:reg[idx];
|.endmacro


|.macro get_vmnull, reg
| mov reg, TC->instance;
| mov reg, MVMINSTANCE:reg->VMNull;
|.endmacro

|.macro get_cur_op, reg
| mov reg, TC->interp_cur_op
| mov reg, [reg]
|.endmacro

|.macro get_string, reg, idx
| mov reg, CU->body.strings;
| mov reg, STRING:reg[idx];
|.endmacro

|.macro is_type_object, reg
| test word OBJECT:reg->header.flags, MVM_CF_TYPE_OBJECT
|.endmacro

|.macro gc_sync_point
| cmp qword TC->gc_status, 0;
| je >1;
| mov ARG1, TC;
| callp &MVM_gc_enter_from_interrupt;
|1:
|.endmacro

|.macro throw_adhoc, msg
| mov ARG1, TC;
| mov64 ARG2, (uintptr_t)(msg);
| callp &MVM_exception_throw_adhoc;
|.endmacro

/* A function prologue is always the same in x86 / x64, becuase
 * we do not provide variable arguments, instead arguments are provided
 * via a frame. All JIT entry points receive a prologue. */
void MVM_jit_emit_prologue(MVMThreadContext *tc, MVMJitGraph *jg,
                           dasm_State **Dst) {
    /* Setup stack */
    | push rbp; // nb, this aligns the stack to 16 bytes again
    | mov rbp, rsp;
    /* allocate stack space: 0x100 bytes = 256 bytes
     *
     * layout: [ a: 0x20 | b: 0x20 | c: 0xa0 | d: 0x20 ]
     * a: space for 4 callee-save registers
     * b: small scratch space
     * c: space for stack arguments to c calls
     * d: reserve space for GPR registers to c calls (win64) or more space for
     * stack arguments (posix) */
    | sub rsp, 0x100;
    /* save callee-save registers */
    | mov [rbp-0x8],  TC;
    | mov [rbp-0x10], CU;
    | mov [rbp-0x18], FRAME;
    | mov [rbp-0x20], WORK;
    /* setup special frame variables */
    | mov TC,   ARG1;
    | mov CU,   ARG2;
    | mov FRAME, TC->cur_frame;
    | mov WORK, FRAME->work;
    /* ARG3 contains our 'entry label' */
    | jmp ARG3
}

/* And a function epilogue is also always the same */
void MVM_jit_emit_epilogue(MVMThreadContext *tc, MVMJitGraph *jg,
                           dasm_State **Dst) {
    | ->exit:
    | mov RV, 0;
    | ->out:
    /* restore callee-save registers */
    | mov TC, [rbp-0x8];
    | mov CU, [rbp-0x10];
    | mov FRAME, [rbp-0x18];
    | mov WORK, [rbp-0x20];
    /* Restore stack */
    | mov rsp, rbp;
    | pop rbp;
    | ret;
}

static MVMuint64 try_emit_gen2_ref(MVMThreadContext *tc, MVMJitGraph *jg,
                                   MVMObject *obj, MVMint16 reg,
                                   dasm_State **Dst) {
    if (!(obj->header.flags & MVM_CF_SECOND_GEN))
        return 0;
    | mov64 TMP1, (uintptr_t)obj;
    | mov WORK[reg], TMP1;
    return 1;
}

/* compile per instruction, can't really do any better yet */
void MVM_jit_emit_primitive(MVMThreadContext *tc, MVMJitGraph *jg,
                            MVMJitPrimitive * prim, dasm_State **Dst) {
    MVMSpeshIns *ins = prim->ins;
    MVMuint16 op = ins->info->opcode;
    MVM_jit_log(tc, "emit opcode: <%s>\n", ins->info->name);
    /* Quite a few of these opcodes are copies. Ultimately, I want to
     * move copies to their own node (MVMJitCopy or such), and reduce
     * the number of copies (and thereby increase the efficiency), but
     * currently that isn't really feasible. */
    switch (op) {
    case MVM_OP_const_i64_16:
    case MVM_OP_const_i64_32: {
        MVMint32 reg = ins->operands[0].reg.orig;
        /* Upgrade to 64 bit */
        MVMint64 val = (op == MVM_OP_const_i64_16 ? (MVMint64)ins->operands[1].lit_i16 :
                        (MVMint64)ins->operands[1].lit_i32);
        | mov qword WORK[reg], val;
        break;
    }
    case MVM_OP_const_i64: {
        MVMint32 reg = ins->operands[0].reg.orig;
        MVMint64 val = ins->operands[1].lit_i64;
        | mov64 TMP1, val;
        | mov WORK[reg], TMP1;
        break;
    }
    case MVM_OP_const_n64: {
        MVMint16 reg = ins->operands[0].reg.orig;
        MVMint64 valbytes = ins->operands[1].lit_i64;
        MVM_jit_log(tc, "store const %f\n", ins->operands[1].lit_n64);
        | mov64 TMP1, valbytes;
        | mov WORK[reg], TMP1;
        break;
    }
    case MVM_OP_const_s: {
         MVMint16 reg = ins->operands[0].reg.orig;
         MVMuint32 idx = ins->operands[1].lit_str_idx;
         MVMStaticFrame *sf = jg->sg->sf;
         MVMString * s = sf->body.cu->body.strings[idx];
         if (!try_emit_gen2_ref(tc, jg, (MVMObject*)s, reg, Dst)) {
             | get_string TMP1, idx;
             | mov WORK[reg], TMP1;
         }
         break;
    }
    case MVM_OP_null: {
        MVMint16 reg = ins->operands[0].reg.orig;
        | get_vmnull TMP1;
        | mov WORK[reg], TMP1;
        break;
    }
    case MVM_OP_getwhat:
    case MVM_OP_getwho: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        | mov TMP1, WORK[obj];
        | mov TMP1, OBJECT:TMP1->st;
        if (op == MVM_OP_getwho) {
            | mov TMP1, STABLE:TMP1->WHO;
            | get_vmnull TMP2;
            | test TMP1, TMP1;
            | cmovz TMP1, TMP2;
        } else {
            | mov TMP1, STABLE:TMP1->WHAT;
        }
        | mov WORK[dst], TMP1;
        break;
    }
    case MVM_OP_getlex: {
        MVMuint16 *lexical_types;
        MVMStaticFrame * sf = jg->sg->sf;
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 idx = ins->operands[1].lex.idx;
        MVMint16 out = ins->operands[1].lex.outers;
        MVMint16 i;
        | mov TMP6, FRAME;
        for (i = 0; i < out; i++) {
            /* I'm going to skip compiling the check whether the outer
             * node really exists, because if the code has run N times
             * correctly, then the outer frame must have existed then,
             * and since this chain is static, it should still exist
             * now.  If it doesn't exist, that means we crash.
             *
             * NB: inlining /might/ make this all wrong! But, if that
             * happens, the interpreter will panic even without JIT */
            | mov TMP6, FRAME:TMP6->outer;
            sf = sf->body.outer;
        }
        /* get array of lexicals */
        | mov TMP5, FRAME:TMP6->env;
        /* read value */
        | mov TMP5, REGISTER:TMP5[idx];
        /* it seems that if at runtime, if the outer frame has been inlined,
         * this /could/ be wrong. But if that is so, the interpreted instruction
         * would also be wrong, because it'd refer to the wrong lexical. */
        lexical_types = (!out && jg->sg->lexical_types ?
                         jg->sg->lexical_types :
                         sf->body.lexical_types);
        MVM_jit_log(tc, "Lexical type of register: %d\n", lexical_types[idx]);
        if (lexical_types[idx] == MVM_reg_obj) {
            MVM_jit_log(tc, "Emit lex vifivy check\n");
            /* if it is zero, check if we need to auto-vivify */
            | test TMP5, TMP5;
            | jnz >1;
            /* setup args */
            | mov ARG1, TC;
            | mov ARG2, TMP6;
            | mov ARG3, idx;
            | callp &MVM_frame_vivify_lexical;
            /* use return value for the result */
            | mov TMP5, RV;
            |1:
        }
        /* store the value */
        | mov WORK[dst], TMP5;
        break;
    }
    case MVM_OP_getlex_no: {
        MVMint16  dst = ins->operands[0].reg.orig;
        MVMuint32 idx = ins->operands[1].lit_str_idx;
        | mov ARG1, TC;
        | get_string ARG2, idx;
        | mov ARG3, MVM_reg_obj;
        | callp &MVM_frame_find_lexical_by_name;
        | test RV, RV;
        | jz >1;
        | mov RV, [RV];
        |1:
        | mov WORK[dst], RV;
        break;
    }
    case MVM_OP_bindlex: {
        MVMint16 idx = ins->operands[0].lex.idx;
        MVMint16 out = ins->operands[0].lex.outers;
        MVMint16 src = ins->operands[1].reg.orig;
        MVMint16 i;
        | mov TMP1, FRAME;
        for (i = 0; i < out; i++) {
            | mov TMP1, FRAME:TMP1->outer;
        }
        | mov TMP1, FRAME:TMP1->env;
        | mov TMP2, WORK[src];
        | mov REGISTER:TMP1[idx], TMP2;
        break;
    }
    case MVM_OP_sp_getarg_o:
    case MVM_OP_sp_getarg_n:
    case MVM_OP_sp_getarg_s:
    case MVM_OP_sp_getarg_i: {
        MVMint32 reg = ins->operands[0].reg.orig;
        MVMuint16 idx = ins->operands[1].callsite_idx;
        | mov TMP1, FRAME->params.args;
        | mov TMP1, REGISTER:TMP1[idx];
        | mov WORK[reg], TMP1;
        break;
    }
    case MVM_OP_sp_p6oget_i:
    case MVM_OP_sp_p6oget_n:
    case MVM_OP_sp_p6oget_s:
    case MVM_OP_sp_p6oget_o:
    case MVM_OP_sp_p6ogetvc_o:
    case MVM_OP_sp_p6ogetvt_o: {
        MVMint16 dst    = ins->operands[0].reg.orig;
        MVMint16 obj    = ins->operands[1].reg.orig;
        MVMint16 offset = ins->operands[2].lit_i16;
        MVMint16 body   = offsetof(MVMP6opaque, body);
        /* load address and object */
        | mov TMP1, WORK[obj];
        | lea TMP2, [TMP1 + (offset + body)];
        | mov TMP4, P6OPAQUE:TMP1->body.replaced;
        | lea TMP5, [TMP4 + offset];
        | test TMP4, TMP4;
        | cmovnz TMP2, TMP5;
        /* TMP2 now contains address of item */
        if (op == MVM_OP_sp_p6oget_o) {
            | mov TMP3, [TMP2];
            | test TMP3, TMP3;
            /* Check if object doesn't point to NULL */
            | jnz >3;
            /* Otherwise load VMNull */
            | get_vmnull TMP3;
            |3:
        } else if (op == MVM_OP_sp_p6ogetvt_o) {
            /* vivify as type object */
            MVMint16 spesh_idx = ins->operands[3].lit_i16;
            | mov TMP3, [TMP2];
            /* check for null */
            | test TMP3, TMP3;
            | jnz >4;
            /* if null, vivify as type object from spesh slot */
            | get_spesh_slot TMP3, spesh_idx;
            /* need to hit write barrier? */
            | check_wb TMP1, TMP3;
            | jz >3;
            | mov qword [rbp-0x28], TMP2; // address
            | mov qword [rbp-0x30], TMP3; // value
            | hit_wb WORK[obj]; // write barrier for header
            | mov TMP3, qword [rbp-0x30];
            | mov TMP2, qword [rbp-0x28];
            |3:
            /* store vivified type value in memory location */
            | mov [TMP2], TMP3;
            |4:
        } else if (op == MVM_OP_sp_p6ogetvc_o) {
            MVMint16 spesh_idx = ins->operands[3].lit_i16;
            | mov TMP3, [TMP2];
            | test TMP3, TMP3;
            | jnz >4;
            /* vivify as clone */
            | mov ARG1, TC;
            | get_spesh_slot ARG2, spesh_idx;
            | callp &MVM_repr_clone;
            | mov TMP3, RV;
            /* reload object and address */
            | mov TMP1, WORK[obj];
            | lea TMP2, [TMP1 + (offset + body)];
            | mov TMP4, P6OPAQUE:TMP1->body.replaced;
            | lea TMP5, [TMP4 + offset];
            | test TMP4, TMP4;
            | cmovnz TMP2, TMP5;
            /* assign with write barrier */
            | check_wb TMP1, TMP3;
            | jz >3;
            | mov qword [rbp-0x28], TMP2; // address
            | mov qword [rbp-0x30], TMP3; // value
            | hit_wb WORK[obj]; // write barrier for header
            | mov TMP3, qword [rbp-0x30];
            | mov TMP2, qword [rbp-0x28];
            |3:
            | mov [TMP2], TMP3;
            /* done */
            |4:
        } else {
            /* the regular case */
            | mov TMP3, [TMP2];
        }
        /* store in local register */
        | mov WORK[dst], TMP3;
        break;
    }
    case MVM_OP_sp_p6obind_i:
    case MVM_OP_sp_p6obind_n:
    case MVM_OP_sp_p6obind_o:
    case MVM_OP_sp_p6obind_s: {
        MVMint16 obj    = ins->operands[0].reg.orig;
        MVMint16 offset = ins->operands[1].callsite_idx;
        MVMint16 val    = ins->operands[2].reg.orig;
        | mov TMP1, WORK[obj];            // object
        | mov TMP2, WORK[val];            // value
        | lea TMP3, P6OPAQUE:TMP1->body;  // body
        | cmp qword P6OBODY:TMP3->replaced, 0;
        | je >1;
        | mov TMP3, P6OBODY:TMP3->replaced; // replaced object body
        |1:
        if (op == MVM_OP_sp_p6obind_o || op == MVM_OP_sp_p6obind_s) {
            /* check if we should hit write barrier */
            | check_wb TMP1, TMP2;
            | jz >2;
            | mov qword [rbp-0x28], TMP2; // store value
            | mov qword [rbp-0x30], TMP3; // store body pointer
            | hit_wb WORK[obj];
            | mov TMP3, qword [rbp-0x30]; // restore body pointer
            | mov TMP2, qword [rbp-0x28]; // restore value
            |2: // done
        }
        | mov [TMP3+offset], TMP2; // store value into body
        break;
    }
    case MVM_OP_getwhere:
    case MVM_OP_set: {
         MVMint32 reg1 = ins->operands[0].reg.orig;
         MVMint32 reg2 = ins->operands[1].reg.orig;
         | mov TMP1, WORK[reg2];
         | mov WORK[reg1], TMP1;
         break;
    }
    case MVM_OP_sp_getspeshslot: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 spesh_idx = ins->operands[1].lit_i16;
        | get_spesh_slot TMP1, spesh_idx;
        | mov WORK[dst], TMP1;
        break;
    }
    case MVM_OP_setdispatcher: {
        MVMint16 src = ins->operands[0].reg.orig;
        | mov TMP1, aword WORK[src];
        | mov aword TC->cur_dispatcher, TMP1;
        break;
    }
    case MVM_OP_takedispatcher: {
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov TMP1, aword TC->cur_dispatcher;
        | mov aword WORK[dst], TMP1;
        | mov aword TC->cur_dispatcher, NULL;
        break;
    }
    case MVM_OP_curcode: {
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov TMP1, aword FRAME->code_ref;
        | mov aword WORK[dst], TMP1;
        break;
    }
    case MVM_OP_getcode: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMuint16 idx = ins->operands[1].coderef_idx;
        | mov TMP1, aword CU->body.coderefs;
        | mov TMP1, aword OBJECTPTR:TMP1[idx];
        | mov aword WORK[dst], TMP1;
        break;
    }
    case MVM_OP_callercode: {
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov TMP1, aword FRAME->caller;
        | test TMP1, TMP1;
        | jz >1;
        | mov TMP1, aword FRAME:TMP1->code_ref;
        |1:
        | mov aword WORK[dst], TMP1;
        break;
    }
    case MVM_OP_hllboxtype_n:
    case MVM_OP_hllboxtype_s:
    case MVM_OP_hllboxtype_i: {
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov TMP1, CU->body.hll_config;
        if (op == MVM_OP_hllboxtype_n) {
            | mov TMP1, aword HLLCONFIG:TMP1->num_box_type;
        } else if (op == MVM_OP_hllboxtype_s) {
            | mov TMP1, aword HLLCONFIG:TMP1->str_box_type;
        } else {
            | mov TMP1, aword HLLCONFIG:TMP1->int_box_type;
        }
        | mov aword WORK[dst], TMP1;
        break;
    }
    case MVM_OP_null_s: {
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov qword WORK[dst], 0;
        break;
     }
    case MVM_OP_isnull_s: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        | mov TMP1, WORK[src];
        | test TMP1, TMP1;
        | setz TMP2b;
        | movzx TMP2, TMP2b;
        | mov qword WORK[dst], TMP2;
        break;
    }

    case MVM_OP_add_i:
    case MVM_OP_sub_i:
    case MVM_OP_bor_i:
    case MVM_OP_band_i:
    case MVM_OP_bxor_i: {
        MVMint32 reg_a = ins->operands[0].reg.orig;
        MVMint32 reg_b = ins->operands[1].reg.orig;
        MVMint32 reg_c = ins->operands[2].reg.orig;
        if (reg_a == reg_b) {
            MVM_jit_log(tc, "accumulator stayed in memory\n");
            | mov rax, WORK[reg_c];
            switch(ins->info->opcode) {
            case MVM_OP_add_i:
                | add WORK[reg_a], rax;
                break;
            case MVM_OP_sub_i:
                | sub WORK[reg_a], rax;
                break;
            case MVM_OP_bor_i:
                | or WORK[reg_a], rax;
                break;
            case MVM_OP_band_i:
                | and WORK[reg_a], rax;
                break;
            case MVM_OP_bxor_i:
                | xor WORK[reg_a], rax;
                break;
            }
        } else {
            | mov rax, WORK[reg_b];
            switch(ins->info->opcode) {
            case MVM_OP_add_i:
                | add rax, WORK[reg_c];
                break;
            case MVM_OP_sub_i:
                | sub rax, WORK[reg_c];
                break;
            case MVM_OP_bor_i:
                | or rax, WORK[reg_c];
                break;
            case MVM_OP_band_i:
                | and rax, WORK[reg_c];
                break;
            case MVM_OP_bxor_i:
                | xor rax, WORK[reg_c];
                break;
            }
            | mov WORK[reg_a], rax;
        }
        break;
    }
    case MVM_OP_mul_i:
    case MVM_OP_blshift_i:
    case MVM_OP_brshift_i: {
        MVMint32 reg_a = ins->operands[0].reg.orig;
        MVMint32 reg_b = ins->operands[1].reg.orig;
        MVMint32 reg_c = ins->operands[2].reg.orig;
        | mov rax, WORK[reg_b];
        switch(ins->info->opcode) {
        case MVM_OP_mul_i:
            | imul rax, WORK[reg_c];
            break;
        case MVM_OP_blshift_i:
            | mov cl, byte WORK[reg_c];
            | shl rax, cl;
            break;
        case MVM_OP_brshift_i:
            | mov cl, byte WORK[reg_c];
            | shr rax, cl;
            break;
        }
        | mov WORK[reg_a], rax;
        break;
    }
    case MVM_OP_div_i:
    case MVM_OP_mod_i: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 a   = ins->operands[1].reg.orig;
        MVMint16 b   = ins->operands[2].reg.orig;
        | mov rcx, WORK[b];
        | test rcx, rcx;
        | jnz >1;
        | throw_adhoc "Division by zero";
        |1:
        // division is safe, proceed
        | mov rax, WORK[a];
        | cqo;  // convert quadword to octoword. look it up :-)
        | idiv rcx; // rcx was the denominator
        if (op == MVM_OP_div_i) {
            | mov TMP3, rax;
            | sub TMP3, 1;
            | cmp rax, 0; // quotient < 0
            | setl ch;
            | test rdx, rdx; // remainder != 0
            | setnz cl;
            | test ch, cl;
            | cmovnz rax, TMP3;
            | mov WORK[dst], rax;
        } else {
            | mov WORK[dst], rdx;
        }
        break;
    }

    case MVM_OP_inc_i: {
         MVMint32 reg = ins->operands[0].reg.orig;
         | add qword WORK[reg], 1;
         break;
    }
    case MVM_OP_dec_i: {
        MVMint32 reg = ins->operands[0].reg.orig;
        | sub qword WORK[reg], 1;
        break;
    }
    case MVM_OP_bnot_i: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        | mov TMP1, WORK[src];
        | not TMP1;
        | mov WORK[dst], TMP1;
        break;
    }
    case MVM_OP_neg_i: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        | mov TMP1, WORK[src];
        | neg TMP1;
        | mov WORK[dst], TMP1;
        break;
    }
    case MVM_OP_add_n:
    case MVM_OP_sub_n:
    case MVM_OP_mul_n:
    case MVM_OP_div_n: {
        MVMint16 reg_a = ins->operands[0].reg.orig;
        MVMint16 reg_b = ins->operands[1].reg.orig;
        MVMint16 reg_c = ins->operands[2].reg.orig;
        /* Copying data to xmm (floating point) registers requires
         * a special move instruction */
        | movsd xmm0, qword WORK[reg_b];
        switch(ins->info->opcode) {
        case MVM_OP_add_n:
            | addsd xmm0, qword WORK[reg_c];
            break;
        case MVM_OP_sub_n:
            | subsd xmm0, qword WORK[reg_c];
            break;
        case MVM_OP_mul_n:
            | mulsd xmm0, qword WORK[reg_c];
            break;
        case MVM_OP_div_n:
            | divsd xmm0, qword WORK[reg_c];
            break;
        }
        | movsd qword WORK[reg_a], xmm0;
        break;
    }
    case MVM_OP_coerce_in: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        /* convert simple integer to double precision */
        | cvtsi2sd xmm0, qword WORK[src];
        | movsd qword WORK[dst], xmm0;
        break;
    }
    case MVM_OP_coerce_ni: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        /* convert double precision to simple intege */
        | cvttsd2si rax, qword WORK[src];
        | mov WORK[dst], rax;
        break;
    }
    case MVM_OP_neg_n: {
        /* Negation is xor-ing the highest byte. Pretty simple right */
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        | mov TMP1, 1;
        | sal TMP1, 63;
        | mov TMP2, qword WORK[src];
        | xor TMP2, TMP1;
        | mov qword WORK[dst], TMP2;
        break;
    }
    case MVM_OP_eq_i:
    case MVM_OP_eqaddr:
    case MVM_OP_ne_i:
    case MVM_OP_lt_i:
    case MVM_OP_le_i:
    case MVM_OP_gt_i:
    case MVM_OP_ge_i: {
        MVMint32 reg_a = ins->operands[0].reg.orig;
        MVMint32 reg_b = ins->operands[1].reg.orig;
        MVMint32 reg_c = ins->operands[2].reg.orig;
        | mov rax, WORK[reg_b];
        /* comparison result in the setting bits in the rflags register */
        | cmp rax, WORK[reg_c];
        /* copy the right comparison bit to the lower byte of the rax
           register */
        switch(ins->info->opcode) {
        case MVM_OP_eqaddr:
        case MVM_OP_eq_i:
            | sete al;
            break;
        case MVM_OP_ne_i:
            | setne al;
            break;
        case MVM_OP_lt_i:
            | setl al;
            break;
        case MVM_OP_le_i:
            | setle al;
            break;
        case MVM_OP_gt_i:
            | setg al;
            break;
        case MVM_OP_ge_i:
            | setge al;
            break;
        }
        /* zero extend al (lower byte) to rax (whole register) */
        | movzx rax, al;
        | mov WORK[reg_a], rax;
        break;
    }
    case MVM_OP_cmp_i : {
        MVMint32 reg_a = ins->operands[0].reg.orig;
        MVMint32 reg_b = ins->operands[1].reg.orig;
        MVMint32 reg_c = ins->operands[2].reg.orig;
        | mov TMP1, WORK[reg_b];
        /* comparison result in the setting bits in the rflags register */
        | cmp TMP1, WORK[reg_c];
        /* copy the right comparison bit to the lower byte of the rax
           register */
        | setg TMP2b;
        | movzx TMP2, TMP2b;
        | setl TMP3b;
        | movzx TMP3, TMP3b;
        | sub TMP2, TMP3;
        | mov WORK[reg_a], TMP2;
        break;
    }
    case MVM_OP_not_i: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        | mov TMP1, WORK[src];
        | test TMP1, TMP1;
        | setz TMP2b;
        | movzx TMP2, TMP2b;
        | mov WORK[dst], TMP2;
        break;
    }
    case MVM_OP_eq_n:
    case MVM_OP_ne_n:
    case MVM_OP_le_n:
    case MVM_OP_lt_n:
    case MVM_OP_ge_n:
    case MVM_OP_gt_n: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 a   = ins->operands[1].reg.orig;
        MVMint16 b   = ins->operands[2].reg.orig;
        if (op == MVM_OP_eq_n) {
            | mov TMP1, 0;
        } else if (op == MVM_OP_ne_n) {
            | mov TMP1, 1;
        }
        if (op == MVM_OP_lt_n || op == MVM_OP_le_n) {
            | movsd xmm0, qword WORK[b];
            | ucomisd xmm0, qword WORK[a];
        } else {
            | movsd xmm0, qword WORK[a];
            | ucomisd xmm0, qword WORK[b];
        }

        if (op == MVM_OP_le_n || op == MVM_OP_ge_n) {
            | setae TMP1b;
        } else if (op == MVM_OP_eq_n) {
            | setnp TMP2b; // zero if either is NaN, 1 otherwise
            | cmove TMP1, TMP2; // if equal, overwrite 0 with 1
        } else if (op == MVM_OP_ne_n) {
            | setp TMP2b; // 1 if either is NaN (in which case they can't be equal)
            | cmove TMP1, TMP2; // if equal, overwrite 1 with IsNan(a) | IsNaN(b)
        } else {
            | seta TMP1b;
        }
        | movzx TMP1, TMP1b;
        | mov WORK[dst], TMP1;
        break;
    }
    case MVM_OP_cmp_n: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 a   = ins->operands[1].reg.orig;
        MVMint16 b   = ins->operands[2].reg.orig;
        | movsd xmm0, qword WORK[a];
        | movsd xmm1, qword WORK[b];
        | ucomisd xmm0, xmm1
        | seta TMP1b;
        | movzx rax, TMP1b;
        | ucomisd xmm1, xmm0
        | seta TMP1b;
        | movzx TMP1, TMP1b;
        | sub rax, TMP1;
        | mov WORK[dst], rax;
        break;
    }
    case MVM_OP_eq_I:
    case MVM_OP_ne_I:
    case MVM_OP_lt_I:
    case MVM_OP_le_I:
    case MVM_OP_gt_I:
    case MVM_OP_ge_I: {
        MVMint32 reg_a = ins->operands[0].reg.orig;
        MVMint32 reg_b = ins->operands[1].reg.orig;
        MVMint32 reg_c = ins->operands[2].reg.orig;
        /* Call the bigint comparison function. */
        | mov ARG1, tc;
        | mov ARG2, WORK[reg_b];
        | mov ARG3, WORK[reg_c];
        | callp &MVM_bigint_cmp;
        /* Handle result by opcode. */
        switch(ins->info->opcode) {
        case MVM_OP_eq_I:
            | cmp RV, MP_EQ
            | sete al;
            break;
        case MVM_OP_ne_I:
            | cmp RV, MP_EQ
            | setne al;
            break;
        case MVM_OP_lt_I:
            | cmp RV, MP_LT
            | sete al;
            break;
        case MVM_OP_le_I:
            | cmp RV, MP_GT
            | setne al;
            break;
        case MVM_OP_gt_I:
            | cmp RV, MP_GT
            | sete al;
            break;
        case MVM_OP_ge_I:
            | cmp RV, MP_LT
            | setne al;
            break;
        }
        /* zero extend al (lower byte) to rax (whole register) */
        | movzx rax, al;
        | mov WORK[reg_a], rax;
        break;
    }
    case MVM_OP_isint:
    case MVM_OP_isnum:
    case MVM_OP_isstr:
    case MVM_OP_islist:
    case MVM_OP_ishash: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        MVMint32 reprid = op == MVM_OP_isint ? MVM_REPR_ID_P6int :
                          op == MVM_OP_isnum ? MVM_REPR_ID_P6num :
                          op == MVM_OP_isstr ? MVM_REPR_ID_P6str :
                          op == MVM_OP_islist ? MVM_REPR_ID_MVMArray :
                     /*  op == MVM_OP_ishash */ MVM_REPR_ID_MVMHash;
        | mov TMP1, aword WORK[obj];
        | test TMP1, TMP1;
        | jz >1;
        | mov TMP1, OBJECT:TMP1->st;
        | mov TMP1, STABLE:TMP1->REPR;
        | cmp qword REPR:TMP1->ID, reprid;
        | jne >1;
        | mov qword WORK[dst], 1;
        | jmp >2;
        |1:
        | mov qword WORK[dst], 0;
        |2:
        break;
    }
    case MVM_OP_sp_boolify_iter_arr: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        | mov TMP1, aword WORK[obj];
        | mov TMP2, MVMITER:TMP1->body.array_state.index;
        | add TMP2, 1;
        | mov TMP3, MVMITER:TMP1->body.array_state.limit;
        /* index - limit will give a carry flag when index < limit */
        | cmp TMP2, TMP3;
        | setl TMP1b;
        | movzx TMP1, TMP1b;
        | mov aword WORK[dst], TMP1;
        break;
    }
    case MVM_OP_sp_boolify_iter_hash: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        | mov TMP1, aword WORK[obj];
        | mov TMP2, MVMITER:TMP1->body.hash_state.next;
        | test TMP2, TMP2;
        | setnz TMP2b;
        | movzx TMP2, TMP2b;
        | mov aword WORK[dst], TMP2;
        break;
    }
    case MVM_OP_objprimspec: {
        MVMint16 dst  = ins->operands[0].reg.orig;
        MVMint16 type = ins->operands[1].reg.orig;
        | mov TMP6, aword WORK[type];
        | test TMP6, TMP6;
        | jz >1;
        | mov TMP6, OBJECT:TMP6->st;
        | mov FUNCTION, STABLE:TMP6->REPR;
        | mov FUNCTION, REPR:FUNCTION->get_storage_spec;
        | mov ARG1, TC;
        | mov ARG2, TMP6;
        | call FUNCTION;
        | mov TMP6w, word STORAGESPEC:RV->boxed_primitive;
        | movzx TMP6, TMP6w;
        |1:
        | mov aword WORK[dst], TMP6;
        break;
    }
    case MVM_OP_isnonnull: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        | mov TMP1, WORK[obj];
        | test TMP1, TMP1;
        | setnz TMP2b;
        | get_vmnull TMP3;
        | cmp TMP1, TMP3;
        | setne TMP3b;
        | and TMP2b, TMP3b;
        | movzx TMP2, TMP2b;
        | mov WORK[dst], TMP2;
        break;
    }
    case MVM_OP_isnull: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        | mov TMP1, WORK[obj];
        | test TMP1, TMP1;
        | setz TMP2b;
        | get_vmnull TMP3;
        | cmp TMP1, TMP3;
        | sete TMP3b;
        | or TMP2b, TMP3b;
        | movzx TMP2, TMP2b;
        | mov WORK[dst], TMP2;
        break;
    }
    case MVM_OP_sp_fastcreate: {
        MVMint16 dst       = ins->operands[0].reg.orig;
        MVMuint16 size     = ins->operands[1].lit_i16;
        MVMint16 spesh_idx = ins->operands[2].lit_i16;
        | mov ARG1, TC;
        | mov ARG2, size;
        | callp &MVM_gc_allocate_zeroed;
        | get_spesh_slot TMP1, spesh_idx;
        | mov aword OBJECT:RV->st, TMP1;  // st is 64 bit (pointer)
        | mov word OBJECT:RV->header.size, size; // object size is 16 bit
        | mov TMP1d, dword TC->thread_id;  // thread id is 32 bit
        | mov dword OBJECT:RV->header.owner, TMP1d; // does this even work?
        | mov aword WORK[dst], RV; // store in local register
        break;
    }
    case MVM_OP_decont: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 src = ins->operands[1].reg.orig;
        | mov TMP5, WORK[src];
        | test TMP5, TMP5;
        // obj is null
        | jz >1;
        | is_type_object TMP5;
        // object is type object (not concrete)
        | jnz >1;
        | mov TMP6, OBJECT:TMP5->st;
        | mov TMP6, STABLE:TMP6->container_spec;
        | test TMP6, TMP6;
        // container spec is zero
        | jz >1;
        | mov ARG1, TC;
        | mov ARG2, TMP5;      // object
        | lea ARG3, WORK[dst]; // destination register
        | mov FUNCTION, CONTAINERSPEC:TMP6->fetch; // get function pointer
        | call FUNCTION;
        | jmp >2;
        |1:
        // otherwise just move the object into the register
        | mov WORK[dst], TMP5;
        |2:
        break;
    }
    case MVM_OP_iscont: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        | mov TMP1, aword WORK[obj];
        | test TMP1, TMP1;
        | jz >1;
        | mov TMP1, OBJECT:TMP1->st;
        | mov TMP1, STABLE:TMP1->container_spec;
        | test TMP1, TMP1;
        |1:
        | setnz TMP1b;
        | movzx TMP1, TMP1b;
        | mov qword WORK[dst], TMP1;
        break;
    }
    case MVM_OP_sp_namedarg_used: {
        MVMuint16 param = ins->operands[0].lit_i16;
        | mov TMP1, FRAME->params.named_used;
        | mov byte U8:TMP1[param], 1;
        break;
    }
    case MVM_OP_sp_findmeth: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        MVMint32 str_idx = ins->operands[2].lit_str_idx;
        MVMuint16 ss_idx = ins->operands[3].lit_i16;
        | get_spesh_slot TMP1, ss_idx;
        | mov TMP2, WORK[obj];
        | mov TMP2, OBJECT:TMP2->st;
        | cmp TMP1, TMP2;
        | jne >1;
        | get_spesh_slot TMP3, ss_idx + 1;
        | mov WORK[dst], TMP3;
        | jmp >2;
        |1:
        | mov ARG1, TC;
        | mov ARG2, WORK[obj];
        | get_string ARG3, str_idx;
        | mov ARG4, ss_idx;
        | lea TMP6, WORK[dst];
        |.if WIN32;
        | mov qword [rsp+0x20], TMP6;
        |.else;
        | mov ARG5, TMP6;
        |.endif
        | callp &MVM_6model_find_method_spesh;
        | test RV, RV;
        | jz >2;
        /* invokish, fall out to the interpreter */
        | mov RV, 1;
        | lea TMP1, [>2];
        | mov aword FRAME->jit_entry_label, TMP1;
        | jmp ->out;
        |2:
        break;
    }
    case MVM_OP_isconcrete: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        | mov TMP1, WORK[obj];
        | test TMP1, TMP1;
        | jz >1;
        | is_type_object TMP1;
        | jnz >1;
        | mov qword WORK[dst], 1;
        | jmp >2;
        |1:
        | mov qword WORK[dst], 0;
        |2:
        break;
    }
    case MVM_OP_takehandlerresult: {
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov TMP1, aword TC->last_handler_result;
        | mov aword WORK[dst], TMP1;
        | mov aword TC->last_handler_result, 0;
        break;
    }
    case MVM_OP_lexoticresult: {
        MVMint16 src = ins->operands[1].reg.orig;
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov TMP1, aword WORK[src];
        | test TMP1, TMP1;
        | jz >1;
        | is_type_object TMP1;
        | jnz >1;
        | mov TMP2, aword OBJECT:TMP1->st;
        | mov TMP2, aword STABLE:TMP2->REPR;
        | cmp aword REPR:TMP2->ID, MVM_REPR_ID_Lexotic;
        | jnz >1;
        | mov TMP2, aword LEXOTIC:TMP1->body.result;
        | mov WORK[dst], TMP2;
        | jmp >2;
        |1:
        /* throw an exception */
        | throw_adhoc "lexoticresult needs a Lexotic";
        /* we never return from an adhoc exception, so no need to deal with that */
        |2:
        break;
    }
    case MVM_OP_scwbdisable: {
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov TMP1d, dword TC->sc_wb_disable_depth;
        | add TMP1d, 1;
        | mov dword TC->sc_wb_disable_depth, TMP1d;
        | mov qword WORK[dst], TMP1;
        break;
    }
    case MVM_OP_scwbenable: {
        MVMint16 dst = ins->operands[0].reg.orig;
        | mov TMP1d, dword TC->sc_wb_disable_depth; // should do zero-extension
        | sub TMP1d, 1;
        | mov dword TC->sc_wb_disable_depth, TMP1d;
        | mov qword WORK[dst], TMP1; 
        break;
    }
    case MVM_OP_assign:
    case MVM_OP_assignunchecked: {
        MVMint16 cont = ins->operands[0].reg.orig;
        MVMint16 obj  = ins->operands[1].reg.orig;
        | mov ARG2, aword WORK[cont];
        | mov FUNCTION, OBJECT:ARG2->st;
        | mov FUNCTION, STABLE:FUNCTION->container_spec;
        | test FUNCTION, FUNCTION;
        | jnz >1;
        | throw_adhoc "Cannot assign to an immutable value";
        |1:
        | mov ARG1, TC;
        | mov ARG3, aword WORK[obj];
        if (op == MVM_OP_assign) {
            | mov FUNCTION, CONTAINERSPEC:FUNCTION->store;
        } else {
            | mov FUNCTION, CONTAINERSPEC:FUNCTION->store_unchecked;
        }
        | call FUNCTION;
        break;
    }
    case MVM_OP_getlexstatic_o:
    case MVM_OP_getlexperinvtype_o: {
        MVMint16 dst  = ins->operands[0].reg.orig;
        MVMint16 name = ins->operands[1].reg.orig;
        | mov ARG1, TC;
        | mov ARG2, aword WORK[name];
        | mov ARG3, MVM_reg_obj;
        | callp &MVM_frame_find_lexical_by_name;
        | test RV, RV;
        | jz >1;
        | mov RV, [RV];
        |1:
        | mov WORK[dst], RV;
        break;
    }
    case MVM_OP_paramnamesused:
        | lea ARG2, FRAME->params;
        | mov TMP5w, word ARGCTX:ARG2->num_pos;
        | cmp TMP5w, word ARGCTX:ARG2->arg_count;
        | je >1;
        | mov ARG1, TC;
        | callp &MVM_args_assert_nameds_used;
        |1:
        break;
    case MVM_OP_assertparamcheck: {
        MVMint16 ok = ins->operands[0].reg.orig;
        | mov TMP1, qword WORK[ok];
        | test TMP1, TMP1;
        | jnz >1;
        | mov ARG1, TC;
        | callp &MVM_args_bind_failed;
        |1:
        break;
    }
    case MVM_OP_prof_enterspesh:
        | mov ARG1, TC;
        | mov ARG2, aword FRAME->static_info;
        | mov ARG3, aword MVM_PROFILE_ENTER_JIT;
        | callp &MVM_profile_log_enter;
        break;
    case MVM_OP_prof_enterinline: {
        MVMint16 spesh_idx = ins->operands[0].lit_i16;
        | mov ARG1, TC;
        | get_spesh_slot ARG2, spesh_idx;
        | mov ARG3, aword MVM_PROFILE_ENTER_JIT_INLINE;
        | callp &MVM_profile_log_enter;
        break;
    }
    case MVM_OP_getobjsc: {
        MVMint16 dst = ins->operands[0].reg.orig;
        MVMint16 obj = ins->operands[1].reg.orig;
        | mov TMP1, aword WORK[obj];
        | mov TMP2d, dword COLLECTABLE:TMP1->sc_forward_u.sc.sc_idx;
        | xor TMP3, TMP3;
        | cmp TMP2d, 0;
        | jle >1;
        | mov TMP3, aword TC->instance;
        | mov TMP3, aword MVMINSTANCE:TMP3->all_scs;
        | mov TMP3, aword [TMP3 + TMP2d * 8];
        | mov TMP3, SCREFBODY:TMP3->sc;
        |1:
        | mov aword WORK[dst], TMP3;
        break;
    }
    case MVM_OP_invokewithcapture: {
	MVMint16 dest    = ins->operands[0].reg.orig;
	MVMint16 code    = ins->operands[1].reg.orig;
	MVMint16 capture = ins->operands[2].reg.orig;
	| mov TMP1, aword WORK[capture];
	/* if (IS_CONCRETE(capture) && REPR(capture)->ID == MVM_REPR_ID_MVMCallCapture) */
	| is_type_object TMP1;
	| jnz >1;
	| mov TMP2, OBJECT:TMP1->st;
	| mov TMP2, STABLE:TMP2->REPR;
	| cmp dword REPR:TMP2->ID, MVM_REPR_ID_MVMCallCapture;
	| je >2;
	|1:
	/* else throw */
	| throw_adhoc "invokewithcapture needs a MVMCallCapture";
	|2:
	/* code = MVM_frame_find_invokee(tc, code, NULL) */
	| mov ARG1, TC;
	| mov ARG2, WORK[code];
	| xor ARG3, ARG3;
	| callp &MVM_frame_find_invokee;

	| mov ARG2, RV; // ARG2 = code
	/* tc->cur_frame->return_value = &GET_REG(cur_op, 2) */
	| lea ARG1, WORK[dest]; // ARG1 is used as scratch space
	| mov aword FRAME->return_value, ARG1;
	/* tc->cur_frame->return_type = MVM_RETURN_OBJ */
	| mov dword FRAME->return_type, MVM_RETURN_OBJ;
	/* tc->cur_frame->return_address = cur_op */
	| get_cur_op ARG1;
	| mov aword FRAME->return_address, ARG1;
	/* STABLE(code)->invoke(tc, code, capture->body.effective_callsite,
                                capture->body.apc->arg) */
	| mov ARG1, TC;
	| mov ARG3, WORK[capture];
	| mov ARG4, aword CAPTURE:ARG3->body.apc;
	| mov ARG4, aword ARGCTX:ARG4->args;
	| mov ARG3, aword CAPTURE:ARG3->body.effective_callsite;
	| mov FUNCTION, OBJECT:ARG2->st;
	| mov FUNCTION, STABLE:FUNCTION->invoke;
	| call FUNCTION;
	/* jumping out is handled by invokish */
	break;
    }
    default:
        MVM_panic(1, "Can't JIT opcode <%s>", ins->info->name);
    }
}



/* Call argument decoder */
static void load_call_arg(MVMThreadContext *tc, MVMJitGraph *jg,
                          MVMJitCallArg arg, dasm_State **Dst) {
    switch(arg.type) {
    case MVM_JIT_INTERP_VAR:
        switch (arg.v.ivar) {
        case MVM_JIT_INTERP_TC:
            | mov TMP6, TC;
            break;
        case MVM_JIT_INTERP_CU:
            | mov TMP6, CU;
            break;
        case MVM_JIT_INTERP_FRAME:
            | mov TMP6, FRAME;
            break;
        case MVM_JIT_INTERP_PARAMS:
            | lea TMP6, FRAME->params;
            break;
        case MVM_JIT_INTERP_CALLER:
            | mov TMP6, aword FRAME->caller;
            break;
        }
        break;
    case MVM_JIT_REG_VAL:
        | mov TMP6, qword WORK[arg.v.reg];
        break;
    case MVM_JIT_REG_VAL_F:
        | mov TMP6, qword WORK[arg.v.reg];
        break;
    case MVM_JIT_REG_ADDR:
        | lea TMP6, WORK[arg.v.reg];
        break;
    case MVM_JIT_STR_IDX:
        | get_string TMP6, arg.v.lit_i64;
        break;
    case MVM_JIT_LITERAL:
        | mov TMP6, arg.v.lit_i64;
        break;
    case MVM_JIT_LITERAL_64:
    case MVM_JIT_LITERAL_PTR:
    case MVM_JIT_LITERAL_F:
        | mov64 TMP6, arg.v.lit_i64;
        break;
    case MVM_JIT_REG_STABLE:
        | mov TMP6, qword WORK[arg.v.reg];
        | mov TMP6, OBJECT:TMP6->st;
        break;
    case MVM_JIT_REG_OBJBODY:
        | mov TMP6, qword WORK[arg.v.reg];
        | lea TMP6, STOOGE:TMP6->data;
        break;
    }
}

static void emit_gpr_arg(MVMThreadContext *tc, MVMJitGraph *jg,
                         MVMint32 i, dasm_State **Dst) {
    switch (i) {
    case 0:
        | mov ARG1, TMP6;
        break;
    case 1:
        | mov ARG2, TMP6;
        break;
    case 2:
        | mov ARG3, TMP6;
        break;
    case 3:
        | mov ARG4, TMP6;
        break;
|.if POSIX
||    case 4:
|        mov ARG5, TMP6;
||       break;
||  case 5:
|      mov ARG6, TMP6;
||     break;
|.endif
    default:
        MVM_exception_throw_adhoc(tc, "JIT: can't store %d arguments in GPR", i);
    }
}

static void emit_sse_arg(MVMThreadContext *tc, MVMJitGraph *jg,
                         MVMint32 i, dasm_State **Dst) {
    switch (i) {
    case 0:
        | movd ARG1F, TMP6;
        break;
    case 1:
        | movd ARG2F, TMP6;
        break;
    case 2:
        | movd ARG3F, TMP6;
        break;
    case 3:
        | movd ARG4F, TMP6;
        break;
|.if POSIX
||    case 4:
|        movd ARG5F, TMP6;
||       break;
||    case 5:
|         movd ARG6F, TMP6;
||        break;
||    case 6:
|        movd ARG5F, TMP6;
||       break;
||    case 7:
|        movd ARG5F, TMP6;
||       break;
|.endif
    default:
        MVM_exception_throw_adhoc(tc, "JIT: can't put  %d arguments in SSE", i);
    }
}

static void emit_stack_arg(MVMThreadContext *tc, MVMJitGraph *jg,
                           MVMint32 arg_size, MVMint32 pos,
                           dasm_State **Dst) {
    /* basically, stack arguments are passed in right-to-left order
       on both POSIX and W64 backends, it seems. Thus the most logical
       thing to do is to count from the stack top upwards. */
    if (pos + arg_size > 160) {
        MVM_exception_throw_adhoc(tc, "JIT: trying to pass arguments "
                                  " in local space (stack top offset: "
                                  " %d, size: %d)", pos, arg_size);
    }
    switch(arg_size) {
    case 1:
        | mov byte [rsp+pos], TMP6b;
        break;
    case 2:
        | mov word [rsp+pos], TMP6w;
        break;
    case 4:
        | mov dword [rsp+pos], TMP6d;
        break;
    case 8:
        | mov qword [rsp+pos], TMP6;
        break;
    default:
        MVM_exception_throw_adhoc(tc, "JIT: can't pass arguments size %d bytes",
                                  arg_size);
    }
}

static void emit_posix_callargs(MVMThreadContext *tc, MVMJitGraph *jg,
                                MVMJitCallArg args[], MVMint32 num_args,
                                dasm_State **Dst) {
    MVMint32 num_gpr = 0, num_fpr = 0, num_stack = 0, i;
    MVMJitCallArg in_gpr[6], in_fpr[8], *on_stack = NULL;
    if (num_args > 6)
        on_stack = MVM_malloc(sizeof(MVMJitCallArg) * (num_args - 6));
    /* divide in gpr, fpr, stack values */
    for (i = 0; i < num_args; i++) {
        switch (args[i].type) {
        case MVM_JIT_INTERP_VAR:
        case MVM_JIT_REG_VAL:
        case MVM_JIT_REG_ADDR:
        case MVM_JIT_REG_OBJBODY:
        case MVM_JIT_REG_STABLE:
        case MVM_JIT_STR_IDX:
        case MVM_JIT_LITERAL:
        case MVM_JIT_LITERAL_64:
        case MVM_JIT_LITERAL_PTR:
            if (num_gpr < 6) {
                in_gpr[num_gpr++] = args[i];
            } else {
                on_stack[num_stack++] = args[i];
            }
            break;
        case MVM_JIT_REG_VAL_F:
        case MVM_JIT_LITERAL_F:
            if (num_fpr < 8) {
                in_fpr[num_fpr++] = args[i];
            } else {
                on_stack[num_stack++] = args[i];
            }
            break;
        }
    }
    for (i = 0; i < num_gpr; i++) {
        load_call_arg(tc, jg, in_gpr[i], Dst);
        emit_gpr_arg(tc, jg, i, Dst);
    }
    for (i = 0; i < num_fpr; i++) {
        load_call_arg(tc, jg, in_fpr[i], Dst);
        emit_sse_arg(tc, jg, i, Dst);
    }
    /* push right-to-left */
    for (i = 0; i < num_stack; i++) {
        load_call_arg(tc, jg, on_stack[i], Dst);
        // I'm not sure this is correct, btw
        emit_stack_arg(tc, jg, 8, i*8, Dst);
    }
    if (on_stack)
        MVM_free(on_stack);
}

static void emit_win64_callargs(MVMThreadContext *tc, MVMJitGraph *jg,
                                MVMJitCallArg args[], MVMint32 num_args,
                                dasm_State **Dst) {
    MVMint32 i;
    MVMint32 num_reg_args = (num_args > 4 ? 4 : num_args);
    for (i = 0; i < num_reg_args; i++) {
        load_call_arg(tc, jg, args[i], Dst);
        if (args[i].type == MVM_JIT_REG_VAL_F ||
            args[i].type == MVM_JIT_LITERAL_F) {
            emit_sse_arg(tc, jg, i, Dst);
        } else {
            emit_gpr_arg(tc, jg, i, Dst);
        }
    }
    for (; i < num_args; i++) {
        load_call_arg(tc, jg, args[i], Dst);
        emit_stack_arg(tc, jg, 8, i * 8, Dst);
    }
}

void MVM_jit_emit_call_c(MVMThreadContext *tc, MVMJitGraph *jg,
                         MVMJitCallC * call_spec, dasm_State **Dst) {

    MVM_jit_log(tc, "emit c call <%d args>\n", call_spec->num_args);
    if (call_spec->has_vargs) {
        MVM_exception_throw_adhoc(tc, "JIT can't handle varargs yet");
    }
    |.if WIN32;
    || emit_win64_callargs(tc, jg, call_spec->args, call_spec->num_args, Dst);
    |.else;
    || emit_posix_callargs(tc, jg, call_spec->args, call_spec->num_args, Dst);
    |.endif
    /* Emit the call. I think we should be able to do something smarter than
     * store the constant into the bytecode, like a data segment. But I'm
     * not sure. */
    | callp call_spec->func_ptr;
    /* right, now determine what to do with the return value */
    switch(call_spec->rv_mode) {
    case MVM_JIT_RV_VOID:
        break;
    case MVM_JIT_RV_INT:
    case MVM_JIT_RV_PTR:
        | mov WORK[call_spec->rv_idx], RV;
        break;
    case MVM_JIT_RV_NUM:
        | movsd qword WORK[call_spec->rv_idx], RVF;
        break;
    case MVM_JIT_RV_DEREF:
        | mov TMP1, [RV];
        | mov WORK[call_spec->rv_idx], TMP1;
        break;
    case MVM_JIT_RV_ADDR:
        /* store local at address */
        | mov TMP1, WORK[call_spec->rv_idx];
        | mov [RV], TMP1;
        break;
    }
}

void MVM_jit_emit_branch(MVMThreadContext *tc, MVMJitGraph *jg,
                         MVMJitBranch * branch, dasm_State **Dst) {
    MVMSpeshIns *ins = branch->ins;
    MVMint32 name = branch->dest;
    /* move gc sync point to the front so as to not have
     * awkward dispatching issues */
    | gc_sync_point;
    if (ins == NULL || ins->info->opcode == MVM_OP_goto) {
        MVM_jit_log(tc, "emit jump to label %d\n", name);
        if (name == MVM_JIT_BRANCH_EXIT) {
            | jmp ->exit
        } else {
            | jmp =>(name)
        }
    } else {
        MVMint16 val = ins->operands[0].reg.orig;
        MVM_jit_log(tc, "emit branch <%s> to label %d\n",
                    ins->info->name, name);
        switch(ins->info->opcode) {
        case MVM_OP_if_i:
            | mov rax, WORK[val];
            | test rax, rax;
            | jnz =>(name); // jump to dynamic label
            break;
        case MVM_OP_unless_i:
            | mov rax, WORK[val];
            | test rax, rax;
            | jz =>(name);
            break;
        case MVM_OP_if_n:
            | movd xmm0, qword WORK[val];
            | xorpd xmm1, xmm1; // make it zero
            | ucomisd xmm0, xmm1;
            | jp =>(name);  // is NaN?
            | jne =>(name); // not equal to zero? we're golden
            break;
        case MVM_OP_unless_n:
            | movd xmm0, qword WORK[val];
            | xorpd xmm1, xmm1; // make it zero
            | ucomisd xmm0, xmm1;
            | jp >1; // is NaN
            | jne >1; // is not zero
            | jmp =>(name); // it is zero yay!
            |1:
            break;
        case MVM_OP_if_s0:
        case MVM_OP_unless_s0:
            | mov ARG1, TC;
            | mov ARG2, WORK[val];
            | callp &MVM_coerce_istrue_s;
            | test RV, RV;
            if (ins->info->opcode == MVM_OP_unless_s0)
                | jz =>(name);
            else
                | jnz =>(name);
            break;
        case MVM_OP_ifnonnull:
            | mov TMP1, WORK[val];
            | test TMP1, TMP1;
            | jz >1;
            | get_vmnull TMP2;
            | cmp TMP1, TMP2;
            | je >1;
            | jmp =>(name);
            |1:
            break;
        case MVM_OP_indexat:
        case MVM_OP_indexnat: {
            MVMint16 offset = ins->operands[1].reg.orig;
            MVMuint32 str_idx = ins->operands[2].lit_str_idx;
            | mov ARG1, TC;
            | mov ARG2, WORK[val];
            | mov ARG3, WORK[offset];
            | get_string ARG4, str_idx;
            | callp &MVM_string_char_at_in_string;
            /* This subtlety is due to the value being overloaded to
             * -2 if it is out of bounds. Note that -1 is passed as a
             * 32 bit integer, but this magically works in a 64 bit
             * comparison because 32 bit values are sign-extended */
            | cmp RV, -1;
            if (ins->info->opcode == MVM_OP_indexat)
                | jle =>(name);
            else {

                | jne =>(name);
            }
            break;
        }
        default:
            MVM_panic(1, "JIT: Can't handle conditional <%s>", ins->info->name);
        }
    }
}

void MVM_jit_emit_label(MVMThreadContext *tc, MVMJitGraph *jg,
                        MVMJitLabel *label, dasm_State **Dst) {
    | =>(label->name):
}

void MVM_jit_emit_guard(MVMThreadContext *tc, MVMJitGraph *jg,
                        MVMJitGuard *guard, dasm_State **Dst) {
    MVMint16 op        = guard->ins->info->opcode;
    MVMint16 obj       = guard->ins->operands[0].reg.orig;
    MVMint16 spesh_idx = guard->ins->operands[1].lit_i16;
    MVM_jit_log(tc, "emit guard <%s>\n", guard->ins->info->name);
    /* load object and spesh slot value */
    | mov TMP1, WORK[obj];
    | get_spesh_slot TMP2, spesh_idx;
    if (op == MVM_OP_sp_guardtype) {
        /* object in queston should be a type object, so it shouldn't
         * be zero, should not be concrete, and the STABLE should be
         * equal to the value in the spesh slot */
        /* check for null */
        | test TMP1, TMP1;
        | jz >1;
        /* check if type object (not concrete) */
        | is_type_object TMP1;
        /* if zero, this is a concrete object, and we should deopt */
        | jz >1;
        /* get stable and compare */
        | cmp TMP2, OBJECT:TMP1->st;
        | jne >1;
        /* we're good, no need to deopt */
    } else if (op == MVM_OP_sp_guardconc) {
        /* object should be a non-null concrete (non-type) object */
        | test TMP1, TMP1;
        | jz >1;
        /* shouldn't be type object */
        | is_type_object TMP1;
        | jnz >1;
        /* should have our stable */
        | cmp TMP2, OBJECT:TMP1->st;
        | jne >1;
    } else if (op == MVM_OP_sp_guardcontconc) {
        MVMint16 val_spesh_idx = guard->ins->operands[2].lit_i16;
        | test TMP1, TMP1;
        | jz >1;
        | is_type_object TMP1;
        | jnz >1;
        | mov FUNCTION, OBJECT:TMP1->st;
        | cmp TMP2, FUNCTION;
        | jne >1;
        | mov FUNCTION, STABLE:FUNCTION->container_spec;
        | mov FUNCTION, CONTAINERSPEC:FUNCTION->fetch;
        | mov ARG2, TMP1;
        | mov ARG1, TC;
        | lea ARG3, [rbp-0x28]; // hurray for scratch space
        | call FUNCTION;
        | mov TMP3, aword [rbp-0x28];
        | test TMP3, TMP3;
        | jz >1;
        | is_type_object TMP3;
        | jnz >1;
        | mov TMP2, OBJECT:TMP3->st;
        | get_spesh_slot TMP1, val_spesh_idx;
        | cmp TMP1, TMP2;
        | jne >1;
    } else if (op == MVM_OP_sp_guardconttype) {
        MVMint16 val_spesh_idx = guard->ins->operands[2].lit_i16;
        | test TMP1, TMP1;
        | jz >1;
        | is_type_object TMP1;
        | jnz >1;
        | mov FUNCTION, OBJECT:TMP1->st;
        | cmp TMP2, FUNCTION;
        | jne >1;
        | mov FUNCTION, STABLE:FUNCTION->container_spec;
        | mov FUNCTION, CONTAINERSPEC:FUNCTION->fetch;
        | mov ARG2, TMP1;
        | mov ARG1, TC;
        | lea ARG3, [rbp-0x28]; // hurray for scratch space
        | call FUNCTION;
        | mov TMP3, aword [rbp-0x28];
        | test TMP3, TMP3;
        | jz >1;
        | is_type_object TMP3;
        // all of this is the same as for guardcontconc, but this time
        // we want to have a type object instead of a concrete object.
        | jz >1;
        | mov TMP2, OBJECT:TMP3->st;
        | get_spesh_slot TMP1, val_spesh_idx;
        | cmp TMP1, TMP2;
        | jne >1;
    }
    /* if we're here, we didn't jump to deopt, so skip it */
    | jmp >2;
    |1:
    /* emit deopt */
    | mov ARG1, TC;
    | mov ARG2, guard->deopt_offset;
    | mov ARG3, guard->deopt_target;
    | callp &MVM_spesh_deopt_one_direct;
    /* tell jit driver we're deopting */
    | mov RV, MVM_JIT_CTRL_DEOPT
    | jmp ->out;
    |2:
}

void MVM_jit_emit_invoke(MVMThreadContext *tc, MVMJitGraph *jg, MVMJitInvoke *invoke,
                         dasm_State **Dst) {
    MVMint16 i;
    MVM_jit_log(tc, "Emit invoke (%d args)\n", invoke->arg_count);
    /* setup the callsite */
    | mov ARG1, TC;
    | mov ARG2, CU;
    | mov ARG3, invoke->callsite_idx;
    | callp &MVM_args_prepare;
    | mov TMP6, RV; // store callsite in tmp6, which we don't use until the end
    /* Store arguments in the buffer. I use TMP5 as it never conflicts
     * with argument passing (like TMP6, but unlike other TMP regs) */
    | mov TMP5, FRAME->args;
    for (i = 0;  i < invoke->arg_count; i++) {
        MVMSpeshIns *ins = invoke->arg_ins[i];
        switch (ins->info->opcode) {
        case MVM_OP_arg_i:
        case MVM_OP_arg_s:
        case MVM_OP_arg_n:
        case MVM_OP_arg_o: {
            MVMint16 dst = ins->operands[0].lit_i16;
            MVMint16 src = ins->operands[1].reg.orig;
            | mov TMP4, WORK[src];
            | mov REGISTER:TMP5[dst], TMP4;
            break;
        }
        case MVM_OP_argconst_n:
        case MVM_OP_argconst_i: {
            MVMint16 dst = ins->operands[0].lit_i16;
            MVMint64 val = ins->operands[1].lit_i64;
            | mov64 TMP4, val;
            | mov REGISTER:TMP5[dst], TMP4;
            break;
        }
        case MVM_OP_argconst_s: {
            MVMint16 dst = ins->operands[0].lit_i16;
            MVMint32 idx = ins->operands[1].lit_str_idx;
            | get_string TMP4, idx;
            | mov REGISTER:TMP5[dst], TMP4;
            break;
        }
        default:
            MVM_panic(1, "JIT invoke: Can't add arg <%s>",
                      ins->info->name);
        }
    }

    /* Setup the frame for returning to our current position */
    if (sizeof(MVMReturnType) == 4) {
        | mov dword FRAME->return_type, invoke->return_type;
    } else {
        MVM_panic(1, "JIT: MVMReturnType has unexpected size");
    }
    /* The register for our return value */
    if (invoke->return_type == MVM_RETURN_VOID) {
        | mov aword FRAME->return_value, NULL;
    } else {
        | lea TMP2, WORK[invoke->return_register];
        | mov aword FRAME->return_value, TMP2;
    }
    /* The return address for the interpreter */
    | get_cur_op TMP2;
    | mov aword FRAME->return_address, TMP2;

    /* The re-entry label for the JIT, so that we continue in the next BB */
    | lea TMP2, [=>(invoke->reentry_label)];
    | mov aword FRAME->jit_entry_label, TMP2;

    /* if we're not fast, then we should get the code from multi resolution */
    if (!invoke->is_fast) {
        /* first, save callsite and args */
        | mov qword [rbp-0x28], TMP5; // args
        | mov qword [rbp-0x30], TMP6; // callsite
        /* setup call MVM_frame_multi_ok(tc, code, &cur_callsite, args); */
        | mov ARG1, TC;
        | mov ARG2, WORK[invoke->code_register]; // code object
        | lea ARG3, [rbp-0x30];                  // &cur_callsite
        | mov ARG4, TMP5;                        // args
        | callp &MVM_frame_find_invokee_multi_ok;
        /* restore callsite, args, RV now holds code object */
        | mov TMP6, [rbp-0x30]; // callsite
        | mov TMP5, [rbp-0x28]; // args
        /* setup args for call to invoke(tc, code, cur_callsite, args) */
        | mov ARG1, TC;
        | mov ARG2, RV;   // code object
        | mov ARG3, TMP6; // callsite
        | mov ARG4, TMP5; // args
        /* get the actual function */
        | mov FUNCTION, OBJECT:RV->st;
        | mov FUNCTION, STABLE:FUNCTION->invoke;
        | call FUNCTION;
    } else {
        /* call MVM_frame_invoke_code */
        | mov ARG1, TC;
        | mov ARG2, WORK[invoke->code_register];
        | mov ARG3, TMP6; // this is the callsite object
        | mov ARG4, invoke->spesh_cand;
        | callp &MVM_frame_invoke_code;
    }
    /* Almost done. jump out into the interprete */
    | mov RV, 1;
    | jmp ->out;
}

void MVM_jit_emit_jumplist(MVMThreadContext *tc, MVMJitGraph *jg,
                           MVMJitJumpList *jumplist, dasm_State **Dst) {
    MVMint32 i;
    MVM_jit_log(tc, "Emit jumplist (%"PRId64" labels)\n", jumplist->num_labels);
    | mov TMP1, WORK[jumplist->reg];
    | cmp TMP1, 0;
    | jl >2;
    | cmp TMP1, jumplist->num_labels;
    | jge >2;
    | imul TMP1, 0x8; // 8 bytes per goto
    | lea TMP2, [>1];
    | add TMP2, TMP1;
    | jmp TMP2;
    |.align 8;
    |1:
    for (i = 0; i < jumplist->num_labels; i++) {
        |=>(jumplist->in_labels[i]):
        | jmp =>(jumplist->out_labels[i]);
        |.align 8;
    }
    |2:
}

void MVM_jit_emit_control(MVMThreadContext *tc, MVMJitGraph *jg,
                          MVMJitControl *ctrl, dasm_State **Dst) {
    if (ctrl->type == MVM_JIT_CONTROL_INVOKISH) {
        MVM_jit_log(tc, "Emit invokish control guard\n");
        | cmp FRAME, TC->cur_frame;
        | je >1;
        | lea TMP1, [>1];
        | mov aword FRAME->jit_entry_label, TMP1;
        | mov RV, 1;
        | jmp ->out;
        |1:
    }
    else if (ctrl->type == MVM_JIT_CONTROL_DYNAMIC_LABEL) {
        MVM_jit_log(tc, "Emit throwish control guard\n");
        /* This pre-loads a label for the next op, so that
         * throwish operators will know where we're throwing
         * from */
        | lea TMP1, [>1];
        | mov aword FRAME->jit_entry_label, TMP1;
        |1:
    }
    else if (ctrl->type == MVM_JIT_CONTROL_THROWISH_PRE) {
        /* Store our current handler, so we can check if something
           was thrown */
        | mov TMP1, aword TC->active_handlers;
        | mov aword [rbp-0x28], TMP1;
        |1:
    }
    else if (ctrl->type == MVM_JIT_CONTROL_THROWISH_POST) {
        /* check if our current handler is the same as it was */
        | mov TMP1, aword TC->active_handlers;
        | mov TMP2, aword [rbp-0x28];
        | cmp TMP1, TMP2;
        | je >1;
        /*if not, fallout to interpreter */
        | mov RV, 1;
        | jmp ->out;
        |1:
    } else if (ctrl->type == MVM_JIT_CONTROL_BREAKPOINT) {
        | int 3;
    } else {
        MVM_panic(1, "Unknown conrtol code: <%s>", ctrl->ins->info->name);
    }
}

